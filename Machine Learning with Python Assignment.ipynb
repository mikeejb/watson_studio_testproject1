{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Import library"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# import necessary library\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline",
            "execution_count": 46,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Read file and data pre-processing"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# input file\nfile_path = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv'\ndf = pd.read_csv(file_path, delimiter=',')\nprint(df.shape)\n# check NaN\nprint('Is there any NaN? ' + str(df.isnull().values.any()))\n# convert data type to int\n# get_dummies for education and gender\ndf_dummies = pd.get_dummies(data=df, columns=['education', 'Gender'])\n# for our y, replace the string value to integer: PAIDOFF=1, COLLECTION=0\ndf_dummies['loan_status'].replace(to_replace=['PAIDOFF', 'COLLECTION'], value=[1,0], inplace=True)\n# convert datetime dtype\ndf_dummies['effective_date'] = pd.to_datetime(df_dummies['effective_date'])\ndf_dummies['due_date'] = pd.to_datetime(df_dummies['due_date'])\ndf_dummies['loan_age'] = df_dummies['due_date'] - df_dummies['effective_date']\ndf_dummies['loan_age_num'] = pd.to_numeric(df_dummies['loan_age'])",
            "execution_count": 47,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(346, 10)\nIs there any NaN? False\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n# # 1. define X and y as array\nX = df_dummies[['Principal', 'terms',\n                'age', 'education_Bechalor',\n                'education_High School or Below', 'education_Master or Above',\n                'education_college', 'Gender_female', 'Gender_male', 'loan_age_num']].values\ny = df_dummies[['loan_status']].values\n# 2. normalize the feature\nX = StandardScaler().fit(X).transform(X)\n# 3. train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n# prepare for final report\nreport_data = [[],[],[],[]]",
            "execution_count": 48,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# KNN Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss, accuracy_score\n# 4. KNN model\ndef checkKNNScore(neighbors, X_train_set, X_test_set, y_train_set, y_test_set):\n    knn = KNeighborsClassifier(n_neighbors=neighbors)\n    knn.fit(X_train_set, y_train_set.ravel())\n    y_hat_set = knn.predict(X_test_set)\n    score = knn.score(X_test_set, y_test_set)\n    return [neighbors, score, y_hat_set, knn]\ntmp_score = 0\ntmp_neighbor = 0\ny_hat = 0\nbest_k = 0\nneighbor_candidate = []\nfor i in range(1,21):\n    result = checkKNNScore(i, X_train, X_test, y_train, y_test)\n#     based on the highest accuracy score and ignore unpredicted label\n    if(result[1]>tmp_score and len(set(result[2]))==2):\n#     if(result[1]>tmp_score):     \n        tmp_score = result[1]\n        tmp_neighbor = result[0]\n        neighbor_candidate.append(tmp_neighbor)\n        y_hat = result[2]\n        best_k = result[3]\nprint('Best mean accuracy score = '+ str(tmp_score) + ' with K(neighbor) = ' + str(tmp_neighbor))\n# KNN accracy check\n# jaccard index\njaccard_index = jaccard_score(y_test, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y_test, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y_test, y_hat)\nprint('log loss: ' + str(log_loss))\nreport_data[0] = [jaccard_index, f1_score, log_loss]\nprint('Classification Report:')\nprint(classification_report(y_test, y_hat))\nprint('Confusion Matrix of KNN:')\nprint(confusion_matrix(y_test, y_hat))",
            "execution_count": 49,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Best mean accuracy score = 0.8142857142857143 with K(neighbor) = 19\njaccard score: 0.8142857142857143\nf1 score: 0.7437570303712036\nlog loss: 6.414481261471447\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        12\n           1       0.83      0.98      0.90        58\n\n    accuracy                           0.81        70\n   macro avg       0.41      0.49      0.45        70\nweighted avg       0.68      0.81      0.74        70\n\nConfusion Matrix of KNN:\n[[ 0 12]\n [ 1 57]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Decision Tree Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n# 5. Decision Tree model\ndef buildDecisionTree(depth, X_train_set, X_test_set, y_train_set, y_test_set):\n    loan_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = depth)\n    loan_tree.fit(X_train_set, y_train_set.ravel())\n    y_hat_set = loan_tree.predict(X_test_set)\n    score = loan_tree.score(X_test_set, y_test_set)\n    return [depth, score, y_hat_set, loan_tree]\ntmp_score = 0\ntmp_depth = 0\ny_hat = 0\nbest_tree = 0\nfor i in range(1,21):\n    result = buildDecisionTree(i, X_train, X_test, y_train, y_test)\n    #     based on the highest accuracy score and ignore unpredicted label\n    if(result[1]>tmp_score and len(set(result[2]))==2):\n#     if(result[1]>tmp_score):\n        tmp_score = result[1]\n        tmp_depth = result[0]\n        y_hat = result[2]\n        best_tree = result[3]\nprint('Best mean accuracy = '+ str(tmp_score) + ' with depth = ' + str(tmp_depth))\n# Decision Tree accracy check\n# jaccard index\njaccard_index = jaccard_score(y_test, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y_test, y_hat, zero_division=1, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y_test, y_hat)\nreport_data[1] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y_test, y_hat))\nprint('Confusion Matrix of Decision Tree:')\nprint(confusion_matrix(y_test, y_hat))",
            "execution_count": 50,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Best mean accuracy = 0.7714285714285715 with depth = 3\njaccard score: 0.7714285714285715\nf1 score: 0.7216589861751151\nlog loss: 7.894714535539047\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        12\n           1       0.82      0.93      0.87        58\n\n    accuracy                           0.77        70\n   macro avg       0.41      0.47      0.44        70\nweighted avg       0.68      0.77      0.72        70\n\nConfusion Matrix of Decision Tree:\n[[ 0 12]\n [ 4 54]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# SVM Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\n# 7. Support Vector Machine\nsvm_model = svm.SVC(kernel='poly', degree=3)\nsvm_model.fit(X_train, y_train.ravel())\ny_hat = svm_model.predict(X_test)\n# SVM accracy check\n# jaccard index\njaccard_index = jaccard_score(y_test, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y_test, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y_test, y_hat)\nreport_data[2] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y_test, y_hat))\nprint('Confusion Matrix of SVM:')\nprint(confusion_matrix(y_test, y_hat))",
            "execution_count": 51,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.8115942028985508\nf1 score: 0.765257142857143\nlog loss: 6.414469838651016\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.33      0.08      0.13        12\n           1       0.84      0.97      0.90        58\n\n    accuracy                           0.81        70\n   macro avg       0.58      0.52      0.51        70\nweighted avg       0.75      0.81      0.77        70\n\nConfusion Matrix of SVM:\n[[ 1 11]\n [ 2 56]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Logistic Regression Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# 8. Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\nlr = LogisticRegression()\nlr.fit(X_train, y_train.ravel())\ny_hat = lr.predict(X_test)\n# y_hat\n# lr_score = lr.score(X_test, y_test)\n# Logistic Regression accracy check\n# jaccard index\njaccard_index = jaccard_score(y_test, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y_test, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y_test, y_hat)\nreport_data[3] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y_test, y_hat))\nprint('Confusion Matrix of Logistics Regression:')\nprint(confusion_matrix(y_test, y_hat))",
            "execution_count": 52,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.8142857142857143\nf1 score: 0.7437570303712036\nlog loss: 6.414481261471447\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        12\n           1       0.83      0.98      0.90        58\n\n    accuracy                           0.81        70\n   macro avg       0.41      0.49      0.45        70\nweighted avg       0.68      0.81      0.74        70\n\nConfusion Matrix of Logistics Regression:\n[[ 0 12]\n [ 1 57]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Final Report of Training Data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# 9. Display report\npd.DataFrame(columns=['jaccard_score', 'f1_score', 'log_loss'], data=report_data, index=['KNN', 'Decision Tree', 'SVM', 'Logistic Regression'])",
            "execution_count": 53,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 53,
                    "data": {
                        "text/plain": "                     jaccard_score  f1_score  log_loss\nKNN                       0.814286  0.743757  6.414481\nDecision Tree             0.771429  0.721659  7.894715\nSVM                       0.811594  0.765257  6.414470\nLogistic Regression       0.814286  0.743757  6.414481",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>jaccard_score</th>\n      <th>f1_score</th>\n      <th>log_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>KNN</th>\n      <td>0.814286</td>\n      <td>0.743757</td>\n      <td>6.414481</td>\n    </tr>\n    <tr>\n      <th>Decision Tree</th>\n      <td>0.771429</td>\n      <td>0.721659</td>\n      <td>7.894715</td>\n    </tr>\n    <tr>\n      <th>SVM</th>\n      <td>0.811594</td>\n      <td>0.765257</td>\n      <td>6.414470</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.814286</td>\n      <td>0.743757</td>\n      <td>6.414481</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Test with test dataset "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# import and read test file\nfile_path = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv'\ndf = pd.read_csv(file_path, delimiter=',')\nprint(df.shape)\n# check NaN\nprint('Is there any NaN? ' + str(df.isnull().values.any()))\n# convert data type to int\n# get_dummies for education and gender\ndf_dummies = pd.get_dummies(data=df, columns=['education', 'Gender'])\n# for our y, replace the string value to integer: PAIDOFF=1, COLLECTION=0\ndf_dummies['loan_status'].replace(to_replace=['PAIDOFF', 'COLLECTION'], value=[1,0], inplace=True)\n# convert datetime dtype\ndf_dummies['effective_date'] = pd.to_datetime(df_dummies['effective_date'])\ndf_dummies['due_date'] = pd.to_datetime(df_dummies['due_date'])\ndf_dummies['loan_age'] = df_dummies['due_date'] - df_dummies['effective_date']\ndf_dummies['loan_age_num'] = pd.to_numeric(df_dummies['loan_age'])",
            "execution_count": 54,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(54, 10)\nIs there any NaN? False\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n# # 1. define X and y as array\nX = df_dummies[['Principal', 'terms',\n                'age', 'education_Bechalor',\n                'education_High School or Below', 'education_Master or Above',\n                'education_college', 'Gender_female', 'Gender_male', 'loan_age_num']].values\ny = df_dummies[['loan_status']].values\n# 2. normalize the feature\nX = StandardScaler().fit(X).transform(X)\n# # 3. train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n# prepare for final report\nreport_data_test = [[],[],[],[]]",
            "execution_count": 55,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# KNN Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# KNN Modeling & Evaluation\n# now we use neighbor=19 according to training data\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss, accuracy_score\n# use trained model to predict test data.\nbest_k.fit(X, y.ravel())\ny_hat = best_k.predict(X)\nscore = best_k.score(X, y)\n# KNN accracy check\n# jaccard index\njaccard_index = jaccard_score(y, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y, y_hat)\nprint('log loss: ' + str(log_loss))\nreport_data_test[0] = [jaccard_index, f1_score, log_loss]\nprint('Classification Report:')\nprint(classification_report(y, y_hat))\nprint('Confusion Matrix of KNN:')\nprint(confusion_matrix(y, y_hat))",
            "execution_count": 56,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.7169811320754716\nf1 score: 0.6491417079652374\nlog loss: 9.594297049819497\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.33      0.07      0.12        14\n           1       0.75      0.95      0.84        40\n\n    accuracy                           0.72        54\n   macro avg       0.54      0.51      0.48        54\nweighted avg       0.64      0.72      0.65        54\n\nConfusion Matrix of KNN:\n[[ 1 13]\n [ 2 38]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Decision Tree Modeling & Evaluation\nNow we also loop for the best depth and score."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Decision Tree Modeling & Evaluation\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n# use trained model to predict\nbest_tree.fit(X, y.ravel())\ny_hat = best_tree.predict(X)\nscore = best_tree.score(X, y)\n# Decision Tree accracy check\n# jaccard index\njaccard_index = jaccard_score(y, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y, y_hat, zero_division=1, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y, y_hat)\nreport_data_test[1] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y, y_hat))\nprint('Confusion Matrix of Decision Tree:')\nprint(confusion_matrix(y, y_hat))",
            "execution_count": 57,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.8085106382978723\nf1 score: 0.8201193520886615\nlog loss: 5.756566384003844\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.78      0.50      0.61        14\n           1       0.84      0.95      0.89        40\n\n    accuracy                           0.83        54\n   macro avg       0.81      0.72      0.75        54\nweighted avg       0.83      0.83      0.82        54\n\nConfusion Matrix of Decision Tree:\n[[ 7  7]\n [ 2 38]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# SVM Modeling & Evaluation\nNow we use kernal=poly with degree=3 according to training data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# SVM Modeling & Evaluation\n# Now we use kernal=poly with degree=3 according to training data\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\n# use trained model to predict test data\nsvm_model.fit(X, y.ravel())\ny_hat = svm_model.predict(X)\n# SVM accracy check\n# jaccard index\njaccard_index = jaccard_score(y, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y, y_hat)\nreport_data_test[2] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y, y_hat))\nprint('Confusion Matrix of SVM:')\nprint(confusion_matrix(y, y_hat))",
            "execution_count": 58,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.7843137254901961\nf1 score: 0.7427039191745074\nlog loss: 7.035839553995365\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.21      0.35        14\n           1       0.78      1.00      0.88        40\n\n    accuracy                           0.80        54\n   macro avg       0.89      0.61      0.62        54\nweighted avg       0.84      0.80      0.74        54\n\nConfusion Matrix of SVM:\n[[ 3 11]\n [ 0 40]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Logistic Regression Modeling & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Logistic Regression Modeling & Evaluation\n# 8. Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\n# use trained model to predict test data\nlr.fit(X, y.ravel())\ny_hat = lr.predict(X)\n# Logistic Regression accracy check\n# jaccard index\njaccard_index = jaccard_score(y, y_hat)\nprint('jaccard score: ' + str(jaccard_index))\n# f1_socre\nf1_score = f1_score(y, y_hat, average='weighted')\nprint('f1 score: ' + str(f1_score))\n# log loss\nlog_loss = log_loss(y, y_hat)\nreport_data_test[3] = [jaccard_index, f1_score, log_loss]\nprint('log loss: ' + str(log_loss))\nprint('Classification Report:')\nprint(classification_report(y, y_hat))\nprint('Confusion Matrix of Logistics Regression:')\nprint(confusion_matrix(y, y_hat))",
            "execution_count": 59,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "jaccard score: 0.74\nf1 score: 0.7288207747977863\nlog loss: 8.315038687187794\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.57      0.29      0.38        14\n           1       0.79      0.93      0.85        40\n\n    accuracy                           0.76        54\n   macro avg       0.68      0.61      0.62        54\nweighted avg       0.73      0.76      0.73        54\n\nConfusion Matrix of Logistics Regression:\n[[ 4 10]\n [ 3 37]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Final Report of Testing Dataset"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# 9. Display report\nprint('Training data report:')\nprint(pd.DataFrame(columns=['jaccard_score', 'f1_score', 'log_loss'], data=report_data, index=['KNN', 'Decision Tree', 'SVM', 'Logistic Regression']))\nprint('\\nTest data report:')\nprint(pd.DataFrame(columns=['jaccard_score', 'f1_score', 'log_loss'], data=report_data_test, index=['KNN', 'Decision Tree', 'SVM', 'Logistic Regression']))",
            "execution_count": 60,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Training data report:\n                     jaccard_score  f1_score  log_loss\nKNN                       0.814286  0.743757  6.414481\nDecision Tree             0.771429  0.721659  7.894715\nSVM                       0.811594  0.765257  6.414470\nLogistic Regression       0.814286  0.743757  6.414481\n\nTest data report:\n                     jaccard_score  f1_score  log_loss\nKNN                       0.716981  0.649142  9.594297\nDecision Tree             0.808511  0.820119  5.756566\nSVM                       0.784314  0.742704  7.035840\nLogistic Regression       0.740000  0.728821  8.315039\n",
                    "name": "stdout"
                }
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}